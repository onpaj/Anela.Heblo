name: üé≠ E2E Nightly Regression Tests

on:
  # Scheduled - Every night at 2:00 AM CET (1:00 AM UTC)
  schedule:
    - cron: '0 1 * * *'  # 1:00 AM UTC = 2:00 AM CET

  # Manual trigger with optional test pattern filter
  workflow_dispatch:
    inputs:
      test_pattern:
        description: 'Test pattern (e.g., "catalog" or "auth", leave empty for all E2E tests)'
        required: false
        default: ''
        type: string
      browser:
        description: 'Browser to run tests on'
        required: false
        default: 'chromium'
        type: choice
        options:
          - 'chromium'
          - 'firefox'
          - 'webkit'
          - 'all'

env:
  STAGING_URL: https://heblo.stg.anela.cz
  NODE_VERSION: '18'

# Required permissions for test reporter to create check runs
permissions:
  checks: write      # Allow creating check runs for test results
  contents: read     # Allow reading repository contents
  issues: write      # Allow creating/updating issues for test failures

jobs:
  # Validate staging health before running tests
  validate-staging-health:
    name: üè• Validate Staging Health
    runs-on: ubuntu-latest

    steps:
      - name: üìä Check Liveness Endpoint
        id: liveness
        run: |
          echo "üîç Checking liveness endpoint..."
          http_code=$(curl -s -o /dev/null -w "%{http_code}" "${{ env.STAGING_URL }}/health/live")

          if [ "$http_code" = "200" ]; then
            echo "‚úÖ Liveness check passed"
            echo "liveness_status=success" >> $GITHUB_OUTPUT
          else
            echo "‚ùå Liveness check failed with status $http_code"
            echo "liveness_status=failed" >> $GITHUB_OUTPUT
            exit 1
          fi

      - name: üìä Check Readiness Endpoint
        id: readiness
        run: |
          echo "üîç Checking readiness endpoint..."
          http_code=$(curl -s -o /dev/null -w "%{http_code}" "${{ env.STAGING_URL }}/health/ready")

          if [ "$http_code" = "200" ]; then
            echo "‚úÖ Readiness check passed"
            echo "readiness_status=success" >> $GITHUB_OUTPUT
          else
            echo "‚ùå Readiness check failed with status $http_code"
            echo "readiness_status=failed" >> $GITHUB_OUTPUT
            exit 1
          fi

      - name: üìä Check General Health Endpoint
        id: health
        run: |
          echo "üîç Checking general health endpoint..."
          http_code=$(curl -s -o /dev/null -w "%{http_code}" "${{ env.STAGING_URL }}/health")

          if [ "$http_code" = "200" ]; then
            echo "‚úÖ General health check passed"
            echo "health_status=success" >> $GITHUB_OUTPUT
          else
            echo "‚ùå General health check failed with status $http_code"
            echo "health_status=failed" >> $GITHUB_OUTPUT
            exit 1
          fi

      - name: üìù Health Check Summary
        run: |
          echo "## üè• Staging Health Check Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Endpoint | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|----------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Liveness | ‚úÖ Passed |" >> $GITHUB_STEP_SUMMARY
          echo "| Readiness | ‚úÖ Passed |" >> $GITHUB_STEP_SUMMARY
          echo "| General Health | ‚úÖ Passed |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "üîó **Staging URL:** ${{ env.STAGING_URL }}" >> $GITHUB_STEP_SUMMARY
          echo "üïê **Validated at:** $(date)" >> $GITHUB_STEP_SUMMARY

  # Run E2E tests against staging
  run-e2e-tests:
    name: üé≠ Run E2E Tests
    runs-on: ubuntu-latest
    needs: validate-staging-health

    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v4

      - name: üì¶ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: üì¶ Install dependencies
        working-directory: ./frontend
        run: npm install --legacy-peer-deps

      - name: üé≠ Install Playwright browsers
        working-directory: ./frontend
        run: |
          if [ "${{ github.event.inputs.browser }}" = "all" ]; then
            npx playwright install --with-deps
          else
            npx playwright install --with-deps ${{ github.event.inputs.browser || 'chromium' }}
          fi

      - name: üìÇ List E2E test files
        working-directory: ./frontend
        run: |
          echo "üîç Available E2E test files:"
          find test/e2e -name "*.spec.ts" -type f | sort
          echo ""

          if [ -n "${{ github.event.inputs.test_pattern }}" ]; then
            echo "üéØ Tests matching pattern '${{ github.event.inputs.test_pattern }}':"
            find test/e2e -name "*${{ github.event.inputs.test_pattern }}*.spec.ts" -type f | sort
          else
            echo "üéØ Running ALL E2E tests"
          fi

      - name: üîê Validate Azure credentials
        working-directory: ./frontend
        run: |
          if [ -z "${{ secrets.E2E_CLIENT_ID }}" ] || [ -z "${{ secrets.E2E_CLIENT_SECRET }}" ]; then
            echo "‚ùå E2E Azure credentials are not configured!"
            echo "Required secrets: E2E_CLIENT_ID, E2E_CLIENT_SECRET"
            exit 1
          fi
          echo "‚úÖ Azure credentials validated"

      - name: üß™ Run E2E tests against staging
        id: run-tests
        working-directory: ./frontend
        continue-on-error: true
        run: |
          # Build test command with optional pattern filter
          if [ -n "${{ github.event.inputs.test_pattern }}" ]; then
            npx playwright test --grep '${{ github.event.inputs.test_pattern }}'
          else
            npx playwright test
          fi
        env:
          PLAYWRIGHT_BASE_URL: ${{ env.STAGING_URL }}
          CI: true
          # Azure service principal credentials for E2E authentication
          E2E_CLIENT_ID: ${{ secrets.E2E_CLIENT_ID }}
          E2E_CLIENT_SECRET: ${{ secrets.E2E_CLIENT_SECRET }}
          AZURE_TENANT_ID: ${{ secrets.REACT_APP_AZURE_TENANT_ID }}

      - name: üìä Publish Test Results to GitHub
        uses: dorny/test-reporter@v1
        if: always()
        with:
          name: 'üé≠ E2E Test Results'
          path: 'frontend/test-results/junit.xml'
          reporter: 'java-junit'
          fail-on-error: false
          fail-on-empty: false

      - name: üìä Upload E2E test results and HTML report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: e2e-nightly-test-results-${{ github.run_number }}
          path: |
            frontend/test-results/
            frontend/playwright-report/
          retention-days: 30

      - name: üì∏ Upload E2E screenshots (failures only)
        uses: actions/upload-artifact@v4
        if: always() && steps.run-tests.outcome == 'failure'
        with:
          name: e2e-nightly-failure-screenshots-${{ github.run_number }}
          path: frontend/test-results/
          retention-days: 30

      - name: üìù Create E2E test summary
        if: always()
        run: |
          echo "## üé≠ E2E Nightly Regression Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Parse JUnit XML for test results
          if [ -f frontend/test-results/junit.xml ]; then
            # Extract test counts from JUnit XML
            TESTS=$(grep -o 'tests="[0-9]*"' frontend/test-results/junit.xml | head -1 | grep -o '[0-9]*')
            FAILURES=$(grep -o 'failures="[0-9]*"' frontend/test-results/junit.xml | head -1 | grep -o '[0-9]*')
            ERRORS=$(grep -o 'errors="[0-9]*"' frontend/test-results/junit.xml | head -1 | grep -o '[0-9]*')
            SKIPPED=$(grep -o 'skipped="[0-9]*"' frontend/test-results/junit.xml | head -1 | grep -o '[0-9]*')

            TOTAL=${TESTS:-0}
            FAILED=$((${FAILURES:-0} + ${ERRORS:-0}))
            SKIP=${SKIPPED:-0}
            PASSED=$((TOTAL - FAILED - SKIP))

            if [ "$FAILED" -eq 0 ]; then
              echo "‚úÖ **All tests passed successfully!**" >> $GITHUB_STEP_SUMMARY
            else
              echo "‚ùå **$FAILED test(s) failed.**" >> $GITHUB_STEP_SUMMARY
            fi

            echo "" >> $GITHUB_STEP_SUMMARY
            echo "| Metric | Count |" >> $GITHUB_STEP_SUMMARY
            echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
            echo "| **Total Tests** | $TOTAL |" >> $GITHUB_STEP_SUMMARY
            echo "| ‚úÖ **Passed** | $PASSED |" >> $GITHUB_STEP_SUMMARY
            echo "| ‚ùå **Failed** | $FAILED |" >> $GITHUB_STEP_SUMMARY
            if [ "$SKIP" -gt 0 ]; then
              echo "| ‚è≠Ô∏è **Skipped** | $SKIP |" >> $GITHUB_STEP_SUMMARY
            fi
            echo "" >> $GITHUB_STEP_SUMMARY

            # List failed tests if any
            if [ "$FAILED" -gt 0 ]; then
              echo "### ‚ùå Failed Tests" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              grep -A 3 '<failure' frontend/test-results/junit.xml | grep 'testcase name=' | sed 's/.*name="\([^"]*\)".*/- `\1`/' >> $GITHUB_STEP_SUMMARY || echo "- Failed to parse test names" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
            fi

            echo "### üìã Test Environment" >> $GITHUB_STEP_SUMMARY
            echo "- **URL:** ${{ env.STAGING_URL }}" >> $GITHUB_STEP_SUMMARY
            echo "- **Browser:** ${{ github.event.inputs.browser || 'chromium' }}" >> $GITHUB_STEP_SUMMARY
            echo "- **Authentication:** Azure Service Principal" >> $GITHUB_STEP_SUMMARY
            echo "- **Executed at:** $(date)" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### üìä View Detailed Results" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Test results are displayed above in the 'Annotations' section** - click on the test reporter check for detailed pass/fail status of each test." >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "For HTML report with screenshots and traces:" >> $GITHUB_STEP_SUMMARY
            echo "1. **Download artifacts**: Go to Actions ‚Üí This workflow run ‚Üí Artifacts" >> $GITHUB_STEP_SUMMARY
            echo "2. **Download** \`e2e-nightly-test-results-${{ github.run_number }}\` artifact" >> $GITHUB_STEP_SUMMARY
            echo "3. **Extract** the ZIP file" >> $GITHUB_STEP_SUMMARY
            echo "4. **Open** \`playwright-report/index.html\` in your browser" >> $GITHUB_STEP_SUMMARY
          else
            echo "‚ö†Ô∏è **JUnit XML report not found - tests may not have run**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Test Status: ${{ steps.run-tests.outcome }}" >> $GITHUB_STEP_SUMMARY
          fi

      - name: üêõ Create or update GitHub issue on failure
        if: always() && steps.run-tests.outcome == 'failure'
        run: |
          # Parse JUnit XML for test results
          if [ -f frontend/test-results/junit.xml ]; then
            TESTS=$(grep -o 'tests="[0-9]*"' frontend/test-results/junit.xml | head -1 | grep -o '[0-9]*')
            FAILURES=$(grep -o 'failures="[0-9]*"' frontend/test-results/junit.xml | head -1 | grep -o '[0-9]*')
            ERRORS=$(grep -o 'errors="[0-9]*"' frontend/test-results/junit.xml | head -1 | grep -o '[0-9]*')

            TOTAL=${TESTS:-0}
            FAILED=$((${FAILURES:-0} + ${ERRORS:-0}))
            PASSED=$((TOTAL - FAILED))
          else
            TOTAL="Unknown"
            FAILED="Unknown"
            PASSED="Unknown"
          fi

          # Search for existing open E2E nightly failure issue
          EXISTING_ISSUE=$(gh issue list \
            --state open \
            --label "e2e-nightly-failure" \
            --json number,title \
            --jq '.[0].number' 2>/dev/null || echo "")

          ISSUE_BODY="## üé≠ E2E Nightly Regression Test Failure

          **Date:** $(date '+%Y-%m-%d %H:%M:%S UTC')
          **Workflow Run:** [#${{ github.run_number }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})

          ### üìä Test Results

          | Metric | Value |
          |--------|-------|
          | **Total Tests** | $TOTAL |
          | **‚úÖ Passed** | $PASSED |
          | **‚ùå Failed** | $FAILED |
          | **Test Environment** | ${{ env.STAGING_URL }} |
          | **Browser** | ${{ github.event.inputs.browser || 'chromium' }} |

          ### üîç Investigation Steps

          1. **View test results directly in workflow:**
             - Go to [this workflow run](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})
             - Click on 'üé≠ E2E Test Results' check for detailed pass/fail status
             - Review annotations for specific test failures

          2. **Download test artifacts for detailed analysis:**
             - Download \`e2e-nightly-test-results-${{ github.run_number }}\` artifact
             - Extract and open \`playwright-report/index.html\` in your browser
             - Check screenshots for visual regressions
             - Review test traces for execution flow

          3. **Verify staging environment:**
             - Ensure staging is accessible: ${{ env.STAGING_URL }}
             - Check recent deployments for breaking changes
             - Verify Azure authentication is working

          ### üîó Links

          - [Workflow Run](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})
          - [Staging Environment](${{ env.STAGING_URL }})
          - [Test Reports (Artifacts)](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}#artifacts)

          ---
          _This issue was automatically created by the E2E nightly regression workflow._
          _It will be automatically closed when tests pass again._"

          if [ -n "$EXISTING_ISSUE" ]; then
            echo "üìù Updating existing issue #$EXISTING_ISSUE"
            gh issue comment "$EXISTING_ISSUE" --body "$ISSUE_BODY"
          else
            echo "üìù Creating new issue for E2E failure"
            gh issue create \
              --title "üé≠ E2E Nightly Regression Tests Failed - $(date '+%Y-%m-%d')" \
              --body "$ISSUE_BODY" \
              --label "e2e-nightly-failure,bug"
          fi
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: ‚úÖ Close GitHub issue on success
        if: always() && steps.run-tests.outcome == 'success'
        run: |
          # Parse JUnit XML for test results
          if [ -f frontend/test-results/junit.xml ]; then
            TESTS=$(grep -o 'tests="[0-9]*"' frontend/test-results/junit.xml | head -1 | grep -o '[0-9]*')
            TOTAL=${TESTS:-0}
          else
            TOTAL="Unknown"
          fi

          # Search for existing open E2E nightly failure issue
          EXISTING_ISSUE=$(gh issue list \
            --state open \
            --label "e2e-nightly-failure" \
            --json number,title \
            --jq '.[0].number' 2>/dev/null || echo "")

          if [ -n "$EXISTING_ISSUE" ]; then
            echo "‚úÖ Closing issue #$EXISTING_ISSUE - tests are now passing"
            gh issue close "$EXISTING_ISSUE" \
              --comment "‚úÖ **E2E tests are now passing!**

          All tests passed in [workflow run #${{ github.run_number }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}).

          **Test Results:**
          - **Total Tests:** $TOTAL
          - **‚úÖ Passed:** $TOTAL
          - **‚ùå Failed:** 0

          The issue has been automatically resolved."
          else
            echo "‚ÑπÔ∏è No open E2E failure issue found"
          fi
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: üì¢ Send Teams notification (optional)
        if: always() && env.TEAMS_WEBHOOK_URL != ''
        run: |
          # Parse JUnit XML for test results
          if [ -f frontend/test-results/junit.xml ]; then
            TESTS=$(grep -o 'tests="[0-9]*"' frontend/test-results/junit.xml | head -1 | grep -o '[0-9]*')
            FAILURES=$(grep -o 'failures="[0-9]*"' frontend/test-results/junit.xml | head -1 | grep -o '[0-9]*')
            ERRORS=$(grep -o 'errors="[0-9]*"' frontend/test-results/junit.xml | head -1 | grep -o '[0-9]*')

            TOTAL=${TESTS:-0}
            FAILED=$((${FAILURES:-0} + ${ERRORS:-0}))
            PASSED=$((TOTAL - FAILED))
          else
            TOTAL=0
            FAILED=0
            PASSED=0
          fi

          # Determine status color and emoji based on test outcome
          if [ "${{ steps.run-tests.outcome }}" = "success" ]; then
            COLOR="28A745"  # Green
            STATUS_EMOJI="‚úÖ"
            STATUS_TEXT="E2E Nightly Tests Passed"
          else
            COLOR="FF0000"  # Red
            STATUS_EMOJI="‚ùå"
            STATUS_TEXT="E2E Nightly Tests Failed"
          fi

          # Create Teams message payload
          PAYLOAD=$(cat <<EOF
          {
            "@type": "MessageCard",
            "@context": "http://schema.org/extensions",
            "themeColor": "$COLOR",
            "summary": "Heblo E2E Nightly - $STATUS_TEXT",
            "sections": [{
              "activityTitle": "$STATUS_EMOJI Heblo E2E Nightly Regression",
              "activitySubtitle": "$STATUS_TEXT",
              "activityImage": "https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png",
              "facts": [
                {
                  "name": "Total Tests",
                  "value": "$TOTAL"
                },
                {
                  "name": "Passed",
                  "value": "‚úÖ $PASSED"
                },
                {
                  "name": "Failed",
                  "value": "‚ùå $FAILED"
                },
                {
                  "name": "Environment",
                  "value": "${{ env.STAGING_URL }}"
                },
                {
                  "name": "Browser",
                  "value": "${{ github.event.inputs.browser || 'chromium' }}"
                },
                {
                  "name": "Executed at",
                  "value": "$(date '+%Y-%m-%d %H:%M:%S UTC')"
                }
              ],
              "markdown": true
            }],
            "potentialAction": [
              {
                "@type": "OpenUri",
                "name": "View Workflow Run",
                "targets": [
                  {
                    "os": "default",
                    "uri": "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
                  }
                ]
              },
              {
                "@type": "OpenUri",
                "name": "View Staging Environment",
                "targets": [
                  {
                    "os": "default",
                    "uri": "${{ env.STAGING_URL }}"
                  }
                ]
              }
            ]
          }
          EOF
          )

          # Send notification to Teams
          RESPONSE=$(curl -X POST "$TEAMS_WEBHOOK_URL" \
            -H "Content-Type: application/json" \
            -d "$PAYLOAD" \
            -s -w "\n%{http_code}")

          HTTP_CODE=$(echo "$RESPONSE" | tail -n1)

          if [ "$HTTP_CODE" = "200" ]; then
            echo "‚úÖ Teams notification sent successfully"
          else
            echo "‚ö†Ô∏è Failed to send Teams notification (HTTP $HTTP_CODE)"
            # Don't fail the workflow if Teams notification fails
            exit 0
          fi
        env:
          TEAMS_WEBHOOK_URL: ${{ secrets.TEAMS_WEBHOOK_URL }}
