name: ðŸŽ­ E2E Nightly Regression Tests

on:
  # Scheduled - Every night at 2:00 AM CET (1:00 AM UTC)
  schedule:
    - cron: '0 1 * * *'  # 1:00 AM UTC = 2:00 AM CET

  # Manual trigger with optional test pattern filter
  workflow_dispatch:
    inputs:
      test_pattern:
        description: 'Test pattern (e.g., "catalog" or "auth", leave empty for all E2E tests)'
        required: false
        default: ''
        type: string
      browser:
        description: 'Browser to run tests on'
        required: false
        default: 'chromium'
        type: choice
        options:
          - 'chromium'
          - 'firefox'
          - 'webkit'
          - 'all'

env:
  STAGING_URL: https://heblo.stg.anela.cz
  NODE_VERSION: '18'

# Required permissions for test reporter to create check runs
permissions:
  checks: write      # Allow creating check runs for test results
  contents: read     # Allow reading repository contents

jobs:
  # Validate staging health before running tests
  validate-staging-health:
    name: ðŸ¥ Validate Staging Health
    runs-on: ubuntu-latest

    steps:
      - name: ðŸ“Š Check Liveness Endpoint
        id: liveness
        run: |
          echo "ðŸ” Checking liveness endpoint..."
          http_code=$(curl -s -o /dev/null -w "%{http_code}" "${{ env.STAGING_URL }}/health/live")

          if [ "$http_code" = "200" ]; then
            echo "âœ… Liveness check passed"
            echo "liveness_status=success" >> $GITHUB_OUTPUT
          else
            echo "âŒ Liveness check failed with status $http_code"
            echo "liveness_status=failed" >> $GITHUB_OUTPUT
            exit 1
          fi

      - name: ðŸ“Š Check Readiness Endpoint
        id: readiness
        run: |
          echo "ðŸ” Checking readiness endpoint..."
          http_code=$(curl -s -o /dev/null -w "%{http_code}" "${{ env.STAGING_URL }}/health/ready")

          if [ "$http_code" = "200" ]; then
            echo "âœ… Readiness check passed"
            echo "readiness_status=success" >> $GITHUB_OUTPUT
          else
            echo "âŒ Readiness check failed with status $http_code"
            echo "readiness_status=failed" >> $GITHUB_OUTPUT
            exit 1
          fi

      - name: ðŸ“Š Check General Health Endpoint
        id: health
        run: |
          echo "ðŸ” Checking general health endpoint..."
          http_code=$(curl -s -o /dev/null -w "%{http_code}" "${{ env.STAGING_URL }}/health")

          if [ "$http_code" = "200" ]; then
            echo "âœ… General health check passed"
            echo "health_status=success" >> $GITHUB_OUTPUT
          else
            echo "âŒ General health check failed with status $http_code"
            echo "health_status=failed" >> $GITHUB_OUTPUT
            exit 1
          fi

      - name: ðŸ“ Health Check Summary
        run: |
          echo "## ðŸ¥ Staging Health Check Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Endpoint | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|----------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Liveness | âœ… Passed |" >> $GITHUB_STEP_SUMMARY
          echo "| Readiness | âœ… Passed |" >> $GITHUB_STEP_SUMMARY
          echo "| General Health | âœ… Passed |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ”— **Staging URL:** ${{ env.STAGING_URL }}" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ• **Validated at:** $(date)" >> $GITHUB_STEP_SUMMARY

  # Run E2E tests against staging with parallel module execution
  run-e2e-tests:
    name: ðŸŽ­ Run E2E Tests (${{ matrix.module }})
    runs-on: ubuntu-latest
    needs: validate-staging-health
    strategy:
      fail-fast: false
      matrix:
        module:
          - catalog
          - issued-invoices
          - stock-operations
          - transport
          - manufacturing
          - core

    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ðŸ“¦ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: ðŸ“¦ Install dependencies
        working-directory: ./frontend
        run: npm install --legacy-peer-deps

      - name: ðŸŽ­ Install Playwright browsers
        working-directory: ./frontend
        run: |
          # Always install chromium for modular execution
          npx playwright install --with-deps chromium

      - name: ðŸ“‚ List E2E test files for module
        working-directory: ./frontend
        run: |
          echo "ðŸ” Test files in module '${{ matrix.module }}':"
          find test/e2e/${{ matrix.module }} -name "*.spec.ts" -type f | sort
          echo ""
          echo "ðŸ“Š Test count: $(find test/e2e/${{ matrix.module }} -name "*.spec.ts" -type f | wc -l)"

      - name: ðŸ” Validate Azure credentials
        working-directory: ./frontend
        run: |
          if [ -z "${{ secrets.E2E_CLIENT_ID }}" ] || [ -z "${{ secrets.E2E_CLIENT_SECRET }}" ]; then
            echo "âŒ E2E Azure credentials are not configured!"
            echo "Required secrets: E2E_CLIENT_ID, E2E_CLIENT_SECRET"
            exit 1
          fi
          echo "âœ… Azure credentials validated"

      - name: ðŸ§ª Run E2E tests for module
        id: run-tests
        working-directory: ./frontend
        continue-on-error: true
        run: |
          # Run tests for specific module
          npx playwright test --project=${{ matrix.module }}
        env:
          PLAYWRIGHT_BASE_URL: ${{ env.STAGING_URL }}
          CI: true
          # Azure service principal credentials for E2E authentication
          E2E_CLIENT_ID: ${{ secrets.E2E_CLIENT_ID }}
          E2E_CLIENT_SECRET: ${{ secrets.E2E_CLIENT_SECRET }}
          AZURE_TENANT_ID: ${{ secrets.REACT_APP_AZURE_TENANT_ID }}

      - name: ðŸ“ Export test results for aggregation
        if: always()
        run: |
          # Parse JSON results and export as artifact metadata
          if [ -f frontend/test-results/results.json ]; then
            TOTAL=$(jq '[ .suites[].suites[]?.specs[]? ] | length' frontend/test-results/results.json 2>/dev/null || echo "0")
            PASSED=$(jq '[ .suites[].suites[]?.specs[]? | select(.ok == true) ] | length' frontend/test-results/results.json 2>/dev/null || echo "0")
            FAILED=$(jq '[ .suites[].suites[]?.specs[]? | select(.ok == false) ] | length' frontend/test-results/results.json 2>/dev/null || echo "0")
            SKIPPED=$(jq '[ .suites[].suites[]?.specs[]? | select(.tests[0].results[0].status == "skipped") ] | length' frontend/test-results/results.json 2>/dev/null || echo "0")

            # Export for downstream jobs
            echo "TOTAL=$TOTAL" >> frontend/test-results/module-summary.env
            echo "PASSED=$PASSED" >> frontend/test-results/module-summary.env
            echo "FAILED=$FAILED" >> frontend/test-results/module-summary.env
            echo "SKIPPED=$SKIPPED" >> frontend/test-results/module-summary.env
            echo "MODULE=${{ matrix.module }}" >> frontend/test-results/module-summary.env

            echo "ðŸ“Š Module ${{ matrix.module }}: $PASSED/$TOTAL passed"
          fi

      - name: ðŸ“Š Publish Test Results to GitHub
        uses: dorny/test-reporter@v1
        if: always()
        with:
          name: 'ðŸŽ­ E2E Test Results - ${{ matrix.module }}'
          path: 'frontend/test-results/junit.xml'
          reporter: 'java-junit'
          fail-on-error: false
          fail-on-empty: false

      - name: ðŸ“Š Upload E2E test results and HTML report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: e2e-test-results-${{ matrix.module }}-${{ github.run_number }}
          path: |
            frontend/test-results/
            frontend/playwright-report/
          retention-days: 30

      - name: ðŸ“¸ Upload E2E screenshots (failures only)
        uses: actions/upload-artifact@v4
        if: always() && steps.run-tests.outcome == 'failure'
        with:
          name: e2e-failure-screenshots-${{ matrix.module }}-${{ github.run_number }}
          path: frontend/test-results/
          retention-days: 30

  # Aggregate results from all modules
  aggregate-results:
    name: ðŸ“Š Aggregate Test Results
    runs-on: ubuntu-latest
    needs: run-e2e-tests
    if: always()

    steps:
      - name: ðŸ“¥ Download all test artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: e2e-test-results-*-${{ github.run_number }}
          path: all-test-results

      - name: ðŸ“ Create comprehensive aggregate summary
        run: |
          echo "## ðŸŽ­ E2E Nightly Regression - Complete Test Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ”— **Staging URL:** ${{ env.STAGING_URL }}" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ• **Executed at:** $(date)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Initialize totals
          GRAND_TOTAL=0
          GRAND_PASSED=0
          GRAND_FAILED=0
          GRAND_SKIPPED=0

          # Collect module data
          declare -A MODULE_TOTAL
          declare -A MODULE_PASSED
          declare -A MODULE_FAILED
          declare -A MODULE_SKIPPED

          # Parse results from each module
          for module_dir in all-test-results/e2e-test-results-*; do
            # Look for module-summary.env file
            if [ -f "$module_dir/test-results/module-summary.env" ]; then
              source "$module_dir/test-results/module-summary.env"

              MODULE_TOTAL[$MODULE]=$TOTAL
              MODULE_PASSED[$MODULE]=$PASSED
              MODULE_FAILED[$MODULE]=$FAILED
              MODULE_SKIPPED[$MODULE]=$SKIPPED

              GRAND_TOTAL=$((GRAND_TOTAL + TOTAL))
              GRAND_PASSED=$((GRAND_PASSED + PASSED))
              GRAND_FAILED=$((GRAND_FAILED + FAILED))
              GRAND_SKIPPED=$((GRAND_SKIPPED + SKIPPED))
            fi
          done

          # Overall status
          if [ "$GRAND_FAILED" -eq 0 ]; then
            echo "### âœ… All Tests Passed!" >> $GITHUB_STEP_SUMMARY
          else
            echo "### âŒ $GRAND_FAILED Test(s) Failed" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY

          # Summary table
          echo "| Module | Total | Passed | Failed | Skipped |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|-------|--------|--------|---------|" >> $GITHUB_STEP_SUMMARY

          # Total row first
          echo "| **TOTAL** | **$GRAND_TOTAL** | **$GRAND_PASSED** | **$GRAND_FAILED** | **$GRAND_SKIPPED** |" >> $GITHUB_STEP_SUMMARY

          # Module rows in consistent order
          for module in catalog issued-invoices stock-operations transport manufacturing core; do
            if [ -n "${MODULE_TOTAL[$module]}" ]; then
              TOTAL=${MODULE_TOTAL[$module]}
              PASSED=${MODULE_PASSED[$module]}
              FAILED=${MODULE_FAILED[$module]}
              SKIPPED=${MODULE_SKIPPED[$module]}

              STATUS_ICON="âœ…"
              if [ "$FAILED" -gt 0 ]; then
                STATUS_ICON="âŒ"
              fi

              echo "| $STATUS_ICON **$module** | $TOTAL | $PASSED | $FAILED | $SKIPPED |" >> $GITHUB_STEP_SUMMARY
            fi
          done

          echo "" >> $GITHUB_STEP_SUMMARY

          # List all failed tests from all modules
          if [ "$GRAND_FAILED" -gt 0 ]; then
            echo "### âŒ Failed Tests" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY

            for module_dir in all-test-results/e2e-test-results-*; do
              if [ -f "$module_dir/test-results/results.json" ]; then
                # Extract module name from directory
                MODULE_NAME=$(basename "$module_dir" | sed 's/e2e-test-results-//' | sed 's/-[0-9]*$//')

                # Check if module has failures
                FAILED_COUNT=$(jq '[ .suites[].suites[]?.specs[]? | select(.ok == false) ] | length' "$module_dir/test-results/results.json" 2>/dev/null || echo "0")

                if [ "$FAILED_COUNT" -gt 0 ]; then
                  echo "#### Module: $MODULE_NAME" >> $GITHUB_STEP_SUMMARY
                  echo "" >> $GITHUB_STEP_SUMMARY

                  # Extract failed test details
                  jq -r '[ .suites[].suites[]?.specs[]? | select(.ok == false) ] | .[] | "**" + .title + "**\n- File: `" + .file + "`\n- Error: " + (.tests[0].results[0].error.message // "No error message") + "\n"' "$module_dir/test-results/results.json" >> $GITHUB_STEP_SUMMARY

                  echo "" >> $GITHUB_STEP_SUMMARY
                fi
              fi
            done
          fi

          echo "### ðŸ“Š View Detailed Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "For detailed HTML reports with screenshots and traces:" >> $GITHUB_STEP_SUMMARY
          echo "1. Go to **Actions** â†’ This workflow run â†’ **Artifacts**" >> $GITHUB_STEP_SUMMARY
          echo "2. Download module-specific artifacts (e.g., \`e2e-test-results-catalog-${{ github.run_number }}\`)" >> $GITHUB_STEP_SUMMARY
          echo "3. Extract and open \`playwright-report/index.html\` in your browser" >> $GITHUB_STEP_SUMMARY
